{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain in /home/work/.local/lib/python3.12/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-community in /home/work/.local/lib/python3.12/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core in /home/work/.local/lib/python3.12/site-packages (0.3.65)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/work/.local/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/work/.local/lib/python3.12/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.4.36)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.11.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/work/.local/lib/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/work/.local/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/work/.local/lib/python3.12/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/work/.local/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/work/.local/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/work/.local/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/work/.local/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/work/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/work/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/work/.local/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/work/.local/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (0.4.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: faiss-cpu in /home/work/.local/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-core\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "from transformers import ElectraModel, AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint path (KOTE Finetuned): ./model/250127_KcElectra_kote.ckpt\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# KOTE íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ (ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ ìˆ˜ì •)\n",
    "###########################\n",
    "best_ckpt_path_kote = './model/250127_KcElectra_kote.ckpt' # Colab ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •\n",
    "print(\"Best checkpoint path (KOTE Finetuned):\", best_ckpt_path_kote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOTETagger í´ë˜ìŠ¤ëŠ” ì´ì „ ì½”ë“œì™€ ë™ì¼\n",
    "class KOTETagger(pl.LightningModule): # KOTETagger í´ë˜ìŠ¤ ì •ì˜ (ì´ì „ ì½”ë“œì—ì„œ ë³µì‚¬)\n",
    "    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.electra = AutoModel.from_pretrained(MODEL_NAME, return_dict=True) # pretrained_electra ì œê±° ë° ì§ì ‘ ë¡œë“œ\n",
    "        self.classifier = nn.Linear(self.electra.config.hidden_size, 44) # num_labels=44 (KOTE ë¼ë²¨ ê°œìˆ˜)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.electra(input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls_output)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(probs, labels)\n",
    "        return loss, probs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, _ = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=INITIAL_LR, weight_decay=WEIGHT_DECAY) # ê°€ì¤‘ì¹˜ ê°ì‡ \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "###########################\n",
    "MODEL_NAME = \"beomi/KcELECTRA-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = [\n",
    "    \"ê°ë™/ê°íƒ„\", \"ê²½ì•…\", \"ê³ ë§ˆì›€\", \"ê³µí¬/ë¬´ì„œì›€\", \"ê·€ì°®ìŒ\", \"ê¸°ëŒ€ê°\", \"ê¸°ì¨\", \"ê¹¨ë‹¬ìŒ\",\n",
    "    \"ë†€ëŒ\", \"ë‹¹í™©/ë‚œì²˜\", \"ë¶€ë„ëŸ¬ì›€\", \"ë¶€ë‹´/ì•ˆ_ë‚´í‚´\", \"ë¶ˆìŒí•¨/ì—°ë¯¼\", \"ë¶ˆì•ˆ/ê±±ì •\", \"ë¶ˆí‰/ë¶ˆë§Œ\",\n",
    "    \"ë¹„ì¥í•¨\", \"ë¿Œë“¯í•¨\", \"ì„œëŸ¬ì›€\", \"ìŠ¬í””\", \"ì‹ ê¸°í•¨/ê´€ì‹¬\", \"ì•„ê»´ì£¼ëŠ”\", \"ì•ˆì‹¬/ì‹ ë¢°\", \"ì•ˆíƒ€ê¹Œì›€/ì‹¤ë§\",\n",
    "    \"ì–´ì´ì—†ìŒ\", \"ì—†ìŒ\", \"ì—­ê²¨ì›€/ì§•ê·¸ëŸ¬ì›€\", \"ìš°ì­ëŒ/ë¬´ì‹œí•¨\", \"ì˜ì‹¬/ë¶ˆì‹ \", \"ì¬ë¯¸ì—†ìŒ\", \"ì ˆë§\",\n",
    "    \"ì¡´ê²½\", \"ì£„ì±…ê°\", \"ì¦ê±°ì›€/ì‹ ë‚¨\", \"ì¦ì˜¤/í˜ì˜¤\", \"ì§€ê¸‹ì§€ê¸‹\", \"ì§œì¦\", \"íŒ¨ë°°/ìê¸°í˜ì˜¤\",\n",
    "    \"í¸ì•ˆ/ì¾Œì \", \"í•œì‹¬í•¨\", \"í–‰ë³µ\", \"í™”ë‚¨/ë¶„ë…¸\", \"í™˜ì˜/í˜¸ì˜\", \"íë­‡í•¨(ê·€ì—¬ì›€/ì˜ˆì¨)\", \"í˜ë“¦/ì§€ì¹¨\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7111f34f3f144809823bab3b4b1cdca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kote_finetuned_model = KOTETagger.load_from_checkpoint(best_ckpt_path_kote)\n",
    "pretrained_electra = kote_finetuned_model.electra # ìˆ˜ì •: electra backboneë§Œ ê°€ì ¸ì˜´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# LightningModule ì •ì˜ (PoetryTagger) (ê¸°ì¡´ ì½”ë“œ í™œìš© + ê°€ì¤‘ì¹˜ ì†ì‹¤ í•¨ìˆ˜, Dropout, Weight Decay, Learning Rate ê°ì†Œ, EarlyStopping patience ì¦ê°€)\n",
    "###########################\n",
    "INITIAL_LR = 1e-5 # í•™ìŠµë¥  ê°ì†Œ (ì›ë˜ 2e-5, 1e-5, 5e-6, 2e-6)\n",
    "DROPOUT_RATE = 0.5 # Dropout ë¹„ìœ¨ (0.1, 0.3, 0.5) - Dropout ì¶”ê°€\n",
    "WEIGHT_DECAY = 0.02 # Weight Decay ê°’ (0.001, 0.01, 0.02) - Weight Decay ì¶”ê°€\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "class PoetryTagger(pl.LightningModule):\n",
    "    def __init__(self, n_training_steps=None, n_warmup_steps=None, dropout_rate=DROPOUT_RATE): # dropout_rate hyperparameter\n",
    "        super().__init__()\n",
    "        self.electra = pretrained_electra # ìˆ˜ì •: KOTE íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ electra backbone ì‚¬ìš©\n",
    "        self.classifier = nn.Sequential( # nn.Sequential ì‚¬ìš©í•˜ì—¬ dropout layer ì¶”ê°€\n",
    "            nn.Linear(self.electra.config.hidden_size, len(emotion_labels)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ) # Classifier ì¶œë ¥ì¸µ í¬ê¸° ìë™ ì¡°ì •\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCELoss() # ê¸°ë³¸ BCE Loss (ê°€ì¤‘ì¹˜ ë¯¸ì ìš©)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.electra(input_ids, attention_mask=attention_mask)\n",
    "        # [CLS] í† í° ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls_output)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(probs, labels)\n",
    "\n",
    "        return loss, probs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        loss, _ = self(input_ids, attention_mask, labels) # forward í•¨ìˆ˜ì— weights ì œê±°\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        loss, outputs = self(input_ids, attention_mask, labels) # validation lossëŠ” ê¸°ì¡´ BCE Loss ì‚¬ìš© (optional)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return {\"val_loss\": loss} # validation metrics are optional\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=INITIAL_LR, weight_decay=WEIGHT_DECAY) # ê°€ì¤‘ì¹˜ ê°ì‡ \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# # Best checkpoint load & Evaluation (poetry-finetuning) (ê¸°ì¡´ ì½”ë“œ í™œìš©)\n",
    "# ###########################\n",
    "def get_latest_version_dir_poetry(base_dir=\"./lightning_logs/poetry-finetuning-3agreements-only\"): # poetry-weighted-finetuning ë¡œ ë³€ê²½\n",
    "    # version_0, version_1, ... version_50 ê²½ë¡œë¥¼ ëª¨ë‘ ì°¾ì•„ ë¦¬ìŠ¤íŠ¸ì—…\n",
    "    version_dirs = glob.glob(os.path.join(base_dir, \"version_*\"))\n",
    "    # ë²„ì „ ìˆ«ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "    version_dirs.sort(key=lambda x: int(x.split(\"_\")[-1]))\n",
    "    if not version_dirs:\n",
    "        raise FileNotFoundError(f\"No version_* directories found under '{base_dir}'\")\n",
    "    # ê°€ì¥ ë§ˆì§€ë§‰(ìˆ«ìê°€ ê°€ì¥ í°) ë²„ì „ ê²½ë¡œ ë°˜í™˜\n",
    "    return version_dirs[-1]\n",
    "\n",
    "def get_latest_checkpoint_poetry(version_dir):\n",
    "    ckpt_dir = os.path.join(version_dir, \"checkpoints\")\n",
    "    ckpt_list = glob.glob(os.path.join(ckpt_dir, \"*.ckpt\"))\n",
    "    ckpt_list.sort()  # íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬\n",
    "    if not ckpt_list:\n",
    "        raise FileNotFoundError(f\"No .ckpt found under '{ckpt_dir}'\")\n",
    "    # ê°€ì¥ ë§ˆì§€ë§‰ íŒŒì¼(ì •ë ¬ ê¸°ì¤€)\n",
    "    return ckpt_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint path (Poetry Weighted Finetuned): ./lightning_logs/poetry-finetuning-3agreements-only/version_0/checkpoints/epoch9-val_loss0.2566.ckpt\n"
     ]
    }
   ],
   "source": [
    "# KPoEM ëª¨ë¸ ë¡œë“œ (local)\n",
    "latest_version_dir_poetry = get_latest_version_dir_poetry(\"./lightning_logs/poetry-finetuning-3agreements-only\") # poetry-weighted-finetuning ë¡œ ë³€ê²½\n",
    "best_ckpt_path_poetry = get_latest_checkpoint_poetry(latest_version_dir_poetry)\n",
    "print(\"Best checkpoint path (Poetry Weighted Finetuned):\", best_ckpt_path_poetry) # poetry-weighted-finetuning ë¡œ ë³€ê²½\n",
    "\n",
    "best_model_poetry = PoetryTagger.load_from_checkpoint(best_ckpt_path_poetry)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "best_model_poetry.to(device)\n",
    "best_model_poetry.eval()\n",
    "best_model_poetry.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"í•˜ë£¨ ì¢…ì¼ ì§€ì¹œ ëª¸ìœ¼ë¡œë§Œ ë– ëŒë‹¤ê°€\n",
    "ë•…ì— ë–¨ì–´ì ¸ ì£½ì§€ ëª»í•œ\n",
    "í–‡ë¹›ë“¤ì€ ì¤„ì§€ì–´ ì–´ë””ë¡œ ê°€ëŠ” ê±¸ê¹Œ\n",
    "\n",
    "ì›…ì„±ì›…ì„± ê°€ì¥ ê·¼ì‹¬ìŠ¤ëŸ¬ìš´ ìƒ‰ê¹”ë¡œ ì„œí–‰í•˜ë©°\n",
    "ì´ë¯¸ ì–´ë‘ ì´ ê¹”ë¦¬ëŠ” ì†Œê°ì¥ìœ¼ë¡œ ëª°ë ¤ë“¤ì–´\n",
    "ëª‡ ì  ííœ´ì§€ë¡œ íƒ€ë“¤ì–´ê°€ëŠ” ì˜¤ë£¨ 6ì‹œì˜ ì°¸í˜¹í•œ í˜•ëŸ‰\n",
    "ë‹¨ í•œ ë²ˆ í›„íšŒë„ ìš©ì„œí•˜ì§€ ì•ŠëŠ” ë¬´ì„œìš´ ì‹œê°„\n",
    "ë°”ëŒì€ ê¸´ ì±„ì°ì„ íœ˜ë‘˜ëŸ¬\n",
    "ì‚´ì•„ì„œ ë¹›ë‚˜ëŠ” ì˜¨ê°– ìƒì§•ì„ ëª°ì•„ë‚´ê³  ìˆë‹¤.\n",
    "\n",
    "ë„ì‹œëŠ” ê³§ í™œìë“¤ì´ ì¼ì œíˆ ë¹ ì ¸ ë‹¬ì•„ë‚˜\n",
    "ì†ë„ ì—†ì´ í˜ì´ì§€ë¥¼ í„ëŸ­ì´ëŠ” í…… ë¹ˆ í•œ ê¶Œ ì±…ì´ ë˜ë¦¬ë¼.\n",
    "ìŠ¹ë¶€ë¥¼ ì•Œ ìˆ˜ ì—†ëŠ” í•˜ë£¨ì™€ì˜ ì‹¸ì›€ì—ì„œ\n",
    "ìš°ë¦¬ëŠ” íŒ¨ë°°í–ˆì„ê¹Œ. ì˜¤ëŠ˜ë„ ë¬¼ì–´ë³´ëŠ” ì‚¬ì†Œí•œ ë¬¼ìŒì€\n",
    "ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ì˜ ì¼ìƒì„ í……í…… í”ë“œëŠ” ê²ƒ.\n",
    "\n",
    "ì˜¤í›„ 6ì‹œì˜ ì†Œê°ì¥ ìœ„ë¡œ ë§ì—†ì´\n",
    "ê²€ì€ ì—°ê¸°ê°€ ìš°ì‚°ì²˜ëŸ¼ í¼ì³ì§€ê³ \n",
    "ì´ì   ìš°ë¦¬ë“¤ì˜ ì°¨ë¡€ì˜€ë‹¤.\n",
    "ë‘ë µì§€ ì•Šì€ê°€.\n",
    "ë°¤ì´ë©´ ê·¸ë¦¼ìë¥¼ ë¹¼ì•—ê²¨ ëˆ„êµ¬ë‚˜ ì•„ë“í•œ í˜¼ìì˜€ë‹¤.\n",
    "\n",
    "ë¬¸ë“ ê±°ë¦¬ë¥¼ ë¹ ë¥´ê²Œ ìŠ¤ì³ê°€ëŠ” ì¼ìƒì˜ ê³µí¬\n",
    "ë³´ì—¬ë‹¤ì˜¤. ì§€ê¸ˆê¹Œì§€ ë¬´ì—‡ì„ í–ˆëŠ”ê°€ ì‚´ì•„ ìˆëŠ” ê·¸ëŒ€ì—¬\n",
    "ì˜¤í›„ 6ì‹œ ìš°ë¦¬ë“¤ ì´ë§ˆì—ë„ ì•„, ë¶‰ì€ ë…¸ì„ì´ ë–´ë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë©´ ìš°ë¦¬ëŠ” ì–´ë””ë¡œ ê°€ì§€?\n",
    "ì•„ì§ë„ í„í„ ì‚´ì•„ ìˆëŠ” ìš°ë¦¬ëŠ” ì´ì œ ê°ì ì–´ë””ë¡œ ê°€ì§€?\n",
    "\"\"\" # ê¸°í˜•ë„ - ë…¸ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotion(sample_text):\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        sample_text,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # ì…ë ¥ í…ì„œ ë˜í•œ ê°™ì€ deviceë¡œ ì´ë™\n",
    "        input_ids = encoding[\"input_ids\"].to(device)\n",
    "        attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "        # forward\n",
    "        _, predictions = best_model_poetry(input_ids, attention_mask)  # best_model_poetry ì‚¬ìš©\n",
    "\n",
    "    # ì¶”ë¡  ê²°ê³¼ë¥¼ CPUë¡œ ê°€ì ¸ì™€ numpyë¡œ ë³€í™˜\n",
    "    predictions = predictions.flatten().cpu().numpy()\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥ (ìˆ«ìê°’ìœ¼ë¡œ ë³€í™˜)\n",
    "    result_dict = {\n",
    "        label_name: float(round(score, 3))  # np.float32 -> float ë³€í™˜\n",
    "        for label_name, score in zip(emotion_labels, predictions)\n",
    "        if score > THRESHOLD\n",
    "    }\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    # print(\"\\n[Sample Inference ê²°ê³¼]\")\n",
    "    # print(result_dict)\n",
    "\n",
    "    return result_dict\n",
    "    # ì˜ˆì‹œ ì¶œë ¥\n",
    "    # {'ë¶ˆì•ˆ/ê±±ì •': 0.336, 'ìŠ¬í””': 0.311}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ê³µí¬/ë¬´ì„œì›€': 0.42800000309944153,\n",
       " 'ë†€ëŒ': 0.30399999022483826,\n",
       " 'ë‹¹í™©/ë‚œì²˜': 0.5070000290870667,\n",
       " 'ë¶€ë‹´/ì•ˆ_ë‚´í‚´': 0.39500001072883606,\n",
       " 'ë¶ˆì•ˆ/ê±±ì •': 0.550000011920929,\n",
       " 'ë¹„ì¥í•¨': 0.3319999873638153,\n",
       " 'ì„œëŸ¬ì›€': 0.35199999809265137,\n",
       " 'ìŠ¬í””': 0.41499999165534973,\n",
       " 'ì‹ ê¸°í•¨/ê´€ì‹¬': 0.30799999833106995,\n",
       " 'ì•ˆíƒ€ê¹Œì›€/ì‹¤ë§': 0.3070000112056732,\n",
       " 'ì˜ì‹¬/ë¶ˆì‹ ': 0.30399999022483826,\n",
       " 'í˜ë“¦/ì§€ì¹¨': 0.33799999952316284}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_emotion(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bllossom ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f39f071ad174c76a83dd7c708cc51bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5c46f45aed49b2ad47db1c108478cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499cfaf79c344a6f92b0048959c5460c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer_bllossom = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer_bllossom.pad_token = tokenizer_bllossom.eos_token  # Blossomì€ pad_tokenì´ ì—†ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbff65671ed4fe29bcf8b2360ab922e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16  # ë˜ëŠ” \"auto\"\n",
    ")\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer_bllossom,\n",
    "    temperature=0.6, #\tìƒì„±ì˜ ë¬´ì‘ìœ„ì„± ì¡°ì ˆ ê³„ìˆ˜\n",
    "    top_p=0.9, # ëˆ„ì  í™•ë¥ ì´ top_p ì´í•˜ì¸ í† í°ë“¤ë§Œ ê³ ë ¤\n",
    "    max_new_tokens=512, #í•œ ë²ˆì— ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ì…ë‹ˆë‹¤. (ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì œì™¸)\n",
    "    repetition_penalty=1.5 # ë°˜ë³µë˜ëŠ” ë‹¨ì–´ì— ëŒ€í•œ í˜ë„í‹°\n",
    ")\n",
    "\n",
    "# 3. LangChainìš© LLM ë˜í¼\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1669/3436462459.py:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "# 4. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "template = \"\"\"\n",
    "### ì‹œìŠ¤í…œ:\n",
    "ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ì‹œì ì¸ í•œêµ­ì–´ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°ì •ì„ í‘œí˜„í•œ ì§§ì€ í•œêµ­ì–´ ì‹œë¥¼ ì¨ì£¼ì„¸ìš”.\n",
    "\n",
    "### ê°ì •: {emotion}\n",
    "### ì‹œ:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"emotion\"],\n",
    "    template=template.strip()\n",
    ")\n",
    "# 5. LLMChain êµ¬ì„±\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1669/2396792340.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain.run(\"ìŠ¬í””\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### ì‹œìŠ¤í…œ:\n",
      "ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ì‹œì ì¸ í•œêµ­ì–´ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°ì •ì„ í‘œí˜„í•œ ì§§ì€ í•œêµ­ì–´ ì‹œë¥¼ ì¨ì£¼ì„¸ìš”.\n",
      "\n",
      "### ê°ì •: ìŠ¬í””\n",
      "### ì‹œ: \n",
      "ìŠ¬í””ì´ ë‚˜ì˜ ë§ˆìŒì„ ê°€ë“ ì±„ìš°ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ê·¸ë‚ ì˜ ì†Œì¤‘í•¨ì„ ìŠì§€ ëª»í•  ë•Œ,\n",
      "ë‚´ ë§ˆìŒì€ í•œì—†ì´ í˜ëŸ¬ë‚˜ì˜µë‹ˆë‹¤.\n",
      "\n",
      "ì‹œì—ì„œ ì‚¬ìš©ëœ ìš”ì†Œ:\n",
      "\n",
      "*   **ê°ì • í‘œí˜„**: \"ìŠ¬í””ì´ ë‚˜ì˜ ë§ˆìŒì„ ê°€ë“ ì±„ìš°ê³  ìˆìŠµë‹ˆë‹¤.\"ëŠ” ìŠ¬í””ì„ ê°•ë ¬í•˜ê²Œ í‘œí˜„í•©ë‹ˆë‹¤.\n",
      "*   **ì‹œê°„ê³¼ ì¶”ì–µ**: \"ê·¸ë‚ ì˜ ì†Œì¤‘í•¨ì„ ìŠì§€ ëª»í•  ë•Œ\"ëŠ” ê³¼ê±°ì˜ ì¶”ì–µì— ëŒ€í•œ ê°ì •ì´ ê¹Šì–´ì§€ëŠ” ëŠë‚Œì„ ì¤ë‹ˆë‹¤.\n",
      "*   **ë¬¼ë¦¬ì  í‘œí˜„**: \"ë‚´ ë§ˆìŒì€ í•œì—†ì´ í˜ëŸ¬ë‚˜ì˜µë‹ˆë‹¤\"ëŠ” ë¬¼ë¦¬ì ìœ¼ë¡œ í˜ëŸ¬ë‚˜ì˜¤ëŠ” ë¬¼ì²´ì™€ ë¹„ìœ í•˜ì—¬ ìŠ¬í””ì˜ ê¹Šì€ ê°ì •ì„ í‘œí˜„í•©ë‹ˆë‹¤. \n",
      "\n",
      "ì´ ì‹œëŠ” ìŠ¬í””ì„ í‘œí˜„í•˜ëŠ” ë° ìˆì–´ ì‹œê°ì , ì‹œê°„ì  ìš”ì†Œë¥¼ í†µí•´ ë” ê¹Šì€ ê°ì •ì„ ì „ë‹¬í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "### ì˜ˆì‹œ ì‹œ:\n",
      "ìŠ¬í””ì´ ë‚˜ì˜ ë§ˆìŒì„ ê°€ë“ ì±„ìš°ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ê·¸ë‚ ì˜ ì†Œì¤‘í•¨ì„ ìŠì§€ ëª»í•  ë•Œ,\n",
      "ë‚´ ë§ˆìŒì€ í•œì—†ì´ í˜ëŸ¬ë‚˜ì˜µë‹ˆë‹¤.\n",
      "ê·¸ë•Œì˜ ëª©ì†Œë¦¬ê°€ ì—¬ì „íˆ ë‚´è€³ì— ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.\n",
      "ê·¸ë¦¬ê³  ê·¸ ëª©ì†Œë¦¬ëŠ” ë‚´ ë§ˆìŒ ì†ìœ¼ë¡œ ë‹¤ì‹œ ë“¤ë ¤ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì‹œì—ì„œëŠ” ìŠ¬í””ë¿ë§Œ ì•„ë‹ˆë¼ ê³¼ê±°ì˜ ì¶”ì–µë„ í•¨ê»˜ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì‹œëŠ” ë”ìš± ê¹Šì€ ê°ì •ì„ ì „ë‹¬í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "### ì˜ˆì‹œ ì‹œ:\n",
      "ìŠ¬í””ì´ ë‚˜ì˜ ë§ˆìŒì„ ê°€ë“ ì±„ìš°ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ê·¸ë‚ ì˜ ì†Œì¤‘í•¨ì„ ìŠì§€ ëª»í•  ë•Œ,\n",
      "ë‚´ ë§ˆìŒì€ í•œì—†ì´ í˜ëŸ¬ë‚˜ì˜µë‹ˆë‹¤.\n",
      "ê·¸ë•Œì˜ ëª©ì†Œë¦¬ê°€ ì—¬ì „íˆ ë‚´è€³ì— ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.\n",
      "ê·¸ë¦¬ê³  ê·¸ ëª©ì†Œë¦¬ëŠ” ë‚´ ë§ˆìŒì†ìœ¼ë¡œ ë‹¤ì‹œ ë“¤ë ¤ì¤ë‹ˆë‹¤.\n",
      "ê·¸ ìˆœê°„ì€ ë‚´ ì‚¶ì˜ ê°€ì¥ ì•„ë¦„ë‹¤ìš´ ìˆœê°„ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì‹œì—ì„œëŠ” ìŠ¬í””ë¿ë§Œ ì•„ë‹ˆë¼ ê³¼ê±°ì˜ ì¶”ì–µë„ í•¨ê»˜ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì‹œëŠ” ë”ìš± ê¹Šì€ ê°ì •ì„ ì „ë‹¬í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "### ì˜ˆì‹œ ì‹œ:\n",
      "ìŠ¬í””ì´ ë‚˜ì˜ ë§ˆìŒì„ ê°€ë“ ì±„ìš°ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ê·¸ë‚ ì˜ ì†Œì¤‘í•¨ì„ ìŠì§€ ëª»í•  ë•Œ,\n",
      "ë‚´ ë§ˆìŒì€ í•œì—†ì´ í˜ëŸ¬ë‚˜ì˜µë‹ˆë‹¤.\n",
      "ê·¸ë•Œì˜ ëª©ì†Œë¦¬ê°€ ì—¬ì „íˆ ë‚´è€³ì—\n"
     ]
    }
   ],
   "source": [
    "# 6. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - ê¸°ë³¸ ì‹œ ìƒì„±í™•ì¸ \n",
    "result = chain.run(\"ìŠ¬í””\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê°ì • ë¶„ë¥˜ ëª¨ë¸ ì ìš©í•˜ì—¬ Blossomìœ¼ë¡œ ì‹œ ìƒì„±(Vector DB ë¯¸ì ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¬ 2. Blossom Prompt Template\n",
    "poetry_template = \"\"\"\n",
    "### ì‹œìŠ¤í…œ:\n",
    "ë‹¹ì‹ ì€ ê°ì • ë¶„ì„ ê²°ê³¼ì— ê¸°ë°˜í•´ ì‹œë¥¼ ì°½ì‘í•˜ëŠ” í•œêµ­ì–´ ì‹œì¸ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ê°ì • ë¶„í¬ë¥¼ ì°¸ê³ í•˜ì—¬ ì‹œë¥¼ í•œ í¸ ì§€ì–´ì£¼ì„¸ìš”.\n",
    "\n",
    "### ê°ì • ë¶„í¬:\n",
    "{emotion_prompt}\n",
    "\n",
    "### ì‹œ:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# poetry_prompt = PromptTemplate(input_variables=[\"emotion_prompt\"], template=poetry_template.strip())\n",
    "# poetry_chain = LLMChain(llm=llm, prompt=poetry_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2ï¸âƒ£ ê°ì • ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# def generate_prompt(emotion_scores):\n",
    "#     top_emotion = max(emotion_scores, key=emotion_scores.get)\n",
    "#     return f\"\"\"ë‹¹ì‹ ì€ ê°ì •ì´ ì„¬ì„¸í•œ í•œêµ­ í˜„ëŒ€ì‹œ ì‘ê°€ì…ë‹ˆë‹¤. \n",
    "# '{top_emotion}'ì˜ ê°ì •ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì§§ì€ ì‹œë¥¼ í•œ í¸ ì°½ì‘í•´ ì£¼ì„¸ìš”.\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_text(d):\n",
    "    return '\\n'.join([f\"{k}: {v}\" for k, v in d.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poetry_section(template):\n",
    "    # Split the template by \"### ì‹œ:\" and extract the part after it\n",
    "    if \"### ì‹œ:\" in template:\n",
    "        poetry_section = template.split(\"### ì‹œ:\")[1].strip()\n",
    "        # Split by lines and return as a list\n",
    "        poetry_lines = poetry_section.splitlines()\n",
    "        return poetry_lines\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ï¸âƒ£ ì „ì²´ íë¦„ í•¨ìˆ˜\n",
    "def emotion_to_poetry(sample_text): #sample text\n",
    "    emotion_scores = classify_emotion(sample_text)\n",
    "    # emotion_prompt = generate_prompt(emotion_scores)\n",
    "    # poem = chain.run(emotion_prompt=emotion_prompt)\n",
    "    # ê°ì • ë”•ì…”ë„ˆë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    emotion_text = dict_to_text(emotion_scores)\n",
    "    \n",
    "    template = \"\"\"\n",
    "    ### ì‹œìŠ¤í…œ:\n",
    "    ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ì‹œì ì¸ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°ì •ëª©ë¡ê³¼ ì •ë„ë¥¼ ë…¹ì—¬ë‚¸ ì§§ì€ í•œêµ­ì–´ ì‹œë¥¼ ì¨ì£¼ì„¸ìš”.\n",
    "    ì£¼ì–´ì§„ ê°ì • ëª©ë¡ì„ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì€ìœ ì™€ ìƒì§•ì„ ì‚¬ìš©í•˜ì—¬ ì°½ì˜ì ìœ¼ë¡œ ê°ì •ì„ í‘œí˜„í•˜ì„¸ìš”.\n",
    "    \n",
    "    ìƒì„±í•œ ì‹œë§Œ ì•Œë ¤ì£¼ì„¸ìš”. ê·¸ ì™¸ì— ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "    ### ê°ì • ëª©ë¡: {emotion}\n",
    "    ### ì‹œ:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"emotion\"],\n",
    "        template=template.strip()\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    result = chain.run(emotion=emotion_text)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"í•˜ë£¨ ì¢…ì¼ ì§€ì¹œ ëª¸ìœ¼ë¡œë§Œ ë– ëŒë‹¤ê°€\n",
    "ë•…ì— ë–¨ì–´ì ¸ ì£½ì§€ ëª»í•œ\n",
    "í–‡ë¹›ë“¤ì€ ì¤„ì§€ì–´ ì–´ë””ë¡œ ê°€ëŠ” ê±¸ê¹Œ\n",
    "\n",
    "ì›…ì„±ì›…ì„± ê°€ì¥ ê·¼ì‹¬ìŠ¤ëŸ¬ìš´ ìƒ‰ê¹”ë¡œ ì„œí–‰í•˜ë©°\n",
    "ì´ë¯¸ ì–´ë‘ ì´ ê¹”ë¦¬ëŠ” ì†Œê°ì¥ìœ¼ë¡œ ëª°ë ¤ë“¤ì–´\n",
    "ëª‡ ì  ííœ´ì§€ë¡œ íƒ€ë“¤ì–´ê°€ëŠ” ì˜¤ë£¨ 6ì‹œì˜ ì°¸í˜¹í•œ í˜•ëŸ‰\n",
    "ë‹¨ í•œ ë²ˆ í›„íšŒë„ ìš©ì„œí•˜ì§€ ì•ŠëŠ” ë¬´ì„œìš´ ì‹œê°„\n",
    "ë°”ëŒì€ ê¸´ ì±„ì°ì„ íœ˜ë‘˜ëŸ¬\n",
    "ì‚´ì•„ì„œ ë¹›ë‚˜ëŠ” ì˜¨ê°– ìƒì§•ì„ ëª°ì•„ë‚´ê³  ìˆë‹¤.\n",
    "\n",
    "ë„ì‹œëŠ” ê³§ í™œìë“¤ì´ ì¼ì œíˆ ë¹ ì ¸ ë‹¬ì•„ë‚˜\n",
    "ì†ë„ ì—†ì´ í˜ì´ì§€ë¥¼ í„ëŸ­ì´ëŠ” í…… ë¹ˆ í•œ ê¶Œ ì±…ì´ ë˜ë¦¬ë¼.\n",
    "ìŠ¹ë¶€ë¥¼ ì•Œ ìˆ˜ ì—†ëŠ” í•˜ë£¨ì™€ì˜ ì‹¸ì›€ì—ì„œ\n",
    "ìš°ë¦¬ëŠ” íŒ¨ë°°í–ˆì„ê¹Œ. ì˜¤ëŠ˜ë„ ë¬¼ì–´ë³´ëŠ” ì‚¬ì†Œí•œ ë¬¼ìŒì€\n",
    "ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ì˜ ì¼ìƒì„ í……í…… í”ë“œëŠ” ê²ƒ.\n",
    "\n",
    "ì˜¤í›„ 6ì‹œì˜ ì†Œê°ì¥ ìœ„ë¡œ ë§ì—†ì´\n",
    "ê²€ì€ ì—°ê¸°ê°€ ìš°ì‚°ì²˜ëŸ¼ í¼ì³ì§€ê³ \n",
    "ì´ì   ìš°ë¦¬ë“¤ì˜ ì°¨ë¡€ì˜€ë‹¤.\n",
    "ë‘ë µì§€ ì•Šì€ê°€.\n",
    "ë°¤ì´ë©´ ê·¸ë¦¼ìë¥¼ ë¹¼ì•—ê²¨ ëˆ„êµ¬ë‚˜ ì•„ë“í•œ í˜¼ìì˜€ë‹¤.\n",
    "\n",
    "ë¬¸ë“ ê±°ë¦¬ë¥¼ ë¹ ë¥´ê²Œ ìŠ¤ì³ê°€ëŠ” ì¼ìƒì˜ ê³µí¬\n",
    "ë³´ì—¬ë‹¤ì˜¤. ì§€ê¸ˆê¹Œì§€ ë¬´ì—‡ì„ í–ˆëŠ”ê°€ ì‚´ì•„ ìˆëŠ” ê·¸ëŒ€ì—¬\n",
    "ì˜¤í›„ 6ì‹œ ìš°ë¦¬ë“¤ ì´ë§ˆì—ë„ ì•„, ë¶‰ì€ ë…¸ì„ì´ ë–´ë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë©´ ìš°ë¦¬ëŠ” ì–´ë””ë¡œ ê°€ì§€?\n",
    "ì•„ì§ë„ í„í„ ì‚´ì•„ ìˆëŠ” ìš°ë¦¬ëŠ” ì´ì œ ê°ì ì–´ë””ë¡œ ê°€ì§€?\n",
    "\"\"\" # ê¸°í˜•ë„ - ë…¸ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6ï¸âƒ£ í…ŒìŠ¤íŠ¸\n",
    "generated_poem = emotion_to_poetry(sample_text)\n",
    "\n",
    "# print(\"ğŸ´ ìƒì„±ëœ ì‹œ:\\n\")\n",
    "# print(generated_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ´ ìƒì„±ëœ ì‹œ:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ì–´ë‘ìš´ ì‹œê°„ì´ ì˜¤ë©´',\n",
       " '    ë¬´ê±°ìš´ ê°€ìŠ´ìœ¼ë¡œ',\n",
       " '    ë¬´ì–¸ê°€ê°€ ë‚´ ì•ˆì— ê¹Šì´ ë¬»ëŠ”ë‹¤',\n",
       " '    ì–´ë‘  ì†ì—ì„œ',\n",
       " '    í•œ ì¥ì˜ ê·¸ë¦¼ì´ ë‚˜íƒ€ë‚˜ë©°',\n",
       " '    ê·¸ ê·¸ë¦¼ì€ ë‚˜ì—ê²Œ',\n",
       " '    ì–´ë–¤ ì˜ë¯¸ë¥¼ ì „ë‹¬í•œë‹¤',\n",
       " '    ì–´ë‘ìš´ ì‹œê°„ì´ ì˜¤ë©´',\n",
       " '    ë¬´ê±°ìš´ ê°€ìŠ´ìœ¼ë¡œ',\n",
       " '    ë¬´ì–¸ê°€ê°€ ë‚´ ì•ˆì— ê¹Šì´ ë¬»ëŠ”ë‹¤',\n",
       " '',\n",
       " '    - [ì‹œì‘] (2024-04-05 12:45:51)',\n",
       " '    - [ì¢…ë£Œ] (2024-04-05 13:00:30) ',\n",
       " '',\n",
       " '    - [ì‘ì„±ì] (2024-04-05 12:45:51)',\n",
       " '    - [ì‘ì„±ì] (2024-04-05 13:00:30)',\n",
       " '',\n",
       " '    - [íŒŒì¼ëª…] (2024-04-05 12:45:51)',\n",
       " '    - [íŒŒì¼ëª…] (2024-04-05 13:00:30)',\n",
       " '',\n",
       " '    - [ì„¤ëª…] (2024-04-05 12:45:51)',\n",
       " '    - [ì„¤ëª…] (2024-04-05 13:00:30) ',\n",
       " '',\n",
       " '    - [ìˆ˜ì •] (2024-04-05 13:00:30)',\n",
       " '    - [ìˆ˜ì •] (2024-04-05 13:00:30) ',\n",
       " '',\n",
       " '    - [ì‚­ì œ] (2024-04-05 13:00:30)',\n",
       " '    - [ì‚­ì œ] (2024-04-05 13:00:30) ',\n",
       " '',\n",
       " '    - [ë’¤ê°€ë ¤ê¸°] (2024-04-05 13:00:30)',\n",
       " '    - [ë’¤ê°€ë ¤ê¸°] (2024-04-05 13:00:30) ',\n",
       " '',\n",
       " '    - [ëŒ“ê¸€] (2024-04-05 13:00:30)',\n",
       " '    - [ëŒ“ê¸€] (2024-04-05 13:00:30) ',\n",
       " '',\n",
       " '    - [ëŒ“ê¸€] (2024-04-05 13:00:30)',\n",
       " '    - [ëŒ“ê¸€] (2024-04-05 13:00:30) ',\n",
       " '',\n",
       " '    - [ëŒ“ê¸€] (2024-04-05 13:00:30)',\n",
       " '    - [ëŒ“ê¸€] (2024-04-05 13:']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ğŸ´ ìƒì„±ëœ ì‹œ:\\n\")\n",
    "extract_poetry_section(generated_poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë²¡í„° DB ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# ê·¼í˜„ëŒ€ì‹œ ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ í™œìš© + ì¼ì¹˜ ë¼ë²¨ë§Œ ì‚¬ìš©)\n",
    "############################ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •)\n",
    "df = pd.read_csv(\"../data/á„á…©á†¼á„’á…¡á†¸á„ƒá…¦á„‹á…µá„á…¥á„‰á…¦á†º_0601_5á„‹á…µá†« - á„’á…¢á†¼á„ƒá…¡á†«á„‹á…±.csv\") # Colab ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •\n",
    "\n",
    "# ê°ì • ë¼ë²¨ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "def labels_to_list(labels_str):\n",
    "    if pd.isna(labels_str):\n",
    "        return []\n",
    "    return [label.strip() for label in labels_str.split(',')]\n",
    "\n",
    "# ë¼ë²¨ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "df['annotator01_label_list'] = df['annotator01'].apply(labels_to_list)\n",
    "df['annotator02_label_list'] = df['annotator02'].apply(labels_to_list)\n",
    "df['annotator03_label_list'] = df['annotator03'].apply(labels_to_list)\n",
    "df['annotator04_label_list'] = df['annotator04'].apply(labels_to_list)\n",
    "df['annotator05_label_list'] = df['annotator05'].apply(labels_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_agreed_by_at_least_k(row, k=3):\n",
    "    \"\"\"\n",
    "    ê° í–‰(row)ì— ëŒ€í•´, ìµœì†Œ këª… ì´ìƒì´ ë™ì˜í•œ ê°ì •ë§Œ ì¶”ì¶œ\n",
    "\n",
    "    Parameters:\n",
    "    - row: annotator label listë“¤ì´ ìˆëŠ” DataFrame row\n",
    "    - k: ë™ì˜í•œ annotator ìµœì†Œ ìˆ˜ (ê¸°ë³¸ 2ëª…)\n",
    "\n",
    "    Returns:\n",
    "    - ê°ì • ë¦¬ìŠ¤íŠ¸ ì¤‘ këª… ì´ìƒì´ ê³µí†µìœ¼ë¡œ ì„ íƒí•œ ê°ì • ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    all_labels = (\n",
    "        row['annotator01_label_list'] +\n",
    "        row['annotator02_label_list'] +\n",
    "        row['annotator03_label_list'] +\n",
    "        row['annotator04_label_list'] +\n",
    "        row['annotator05_label_list']\n",
    "    )\n",
    "    counter = pd.Series(all_labels).value_counts() # ê°ì •ë³„ ê°œìˆ˜ ì„¸ê¸°\n",
    "    return [label for label, count in counter.items() if count >= k] # këª… ì´ìƒì´ ë™ì˜í•œ ê°ì • ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ë¹„ì¥í•¨]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ë¹„ì¥í•¨, ë¶€ë„ëŸ¬ì›€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ê¸°ëŒ€ê°]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[íŒ¨ë°°/ìê¸°í˜ì˜¤, ì ˆë§, ìŠ¬í””, í˜ë“¦/ì§€ì¹¨]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ê¸°ì¨, ê¸°ëŒ€ê°, ì•„ê»´ì£¼ëŠ”]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ë¹„ì¥í•¨, ë¶ˆìŒí•¨/ì—°ë¯¼, ì•„ê»´ì£¼ëŠ”]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ë¹„ì¥í•¨]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ê¸°ëŒ€ê°, ê°ë™/ê°íƒ„]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ìŠ¬í””]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              common_labels\n",
       "0                     [ë¹„ì¥í•¨]\n",
       "1               [ë¹„ì¥í•¨, ë¶€ë„ëŸ¬ì›€]\n",
       "2                     [ê¸°ëŒ€ê°]\n",
       "3  [íŒ¨ë°°/ìê¸°í˜ì˜¤, ì ˆë§, ìŠ¬í””, í˜ë“¦/ì§€ì¹¨]\n",
       "4           [ê¸°ì¨, ê¸°ëŒ€ê°, ì•„ê»´ì£¼ëŠ”]\n",
       "5       [ë¹„ì¥í•¨, ë¶ˆìŒí•¨/ì—°ë¯¼, ì•„ê»´ì£¼ëŠ”]\n",
       "6                        []\n",
       "7                     [ë¹„ì¥í•¨]\n",
       "8              [ê¸°ëŒ€ê°, ê°ë™/ê°íƒ„]\n",
       "9                      [ìŠ¬í””]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2ëª… ì´ìƒ ë™ì˜í•œ ê°ì • ë¦¬ìŠ¤íŠ¸ë¡œ ìƒˆ ì»¬ëŸ¼ ìƒì„±\n",
    "df['common_labels'] = df.apply(lambda row: get_labels_agreed_by_at_least_k(row, k=3), axis=1)\n",
    "\n",
    "df[['common_labels']].head(10) # 3ëª… ì´ìƒ ë™ì˜í•œ ê°ì • ë¦¬ìŠ¤íŠ¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1416/3686308332.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_agreement['labels'] = df_agreement['common_labels']\n"
     ]
    }
   ],
   "source": [
    "# ì¼ì¹˜í•˜ëŠ” ë¼ë²¨ë§Œ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§\n",
    "df_agreement = df[df['common_labels'].map(len) > 0].reset_index(drop=True) # agreement ì»¬ëŸ¼ì´ ë¹„ì–´ìˆì§€ ì•Šì€ í–‰ë§Œ ì„ íƒ\n",
    "\n",
    "# 1ì°¨ ë°ì´í„° csv íŒŒì¼ì—ì„œ 'agreement' ì»¬ëŸ¼ì´ ë¹„ì–´ ìˆì§€ ì•Šì€ í–‰ë§Œ ì„ íƒ\n",
    "df_agreement = df[df['common_labels'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# 'agreement' ì»¬ëŸ¼ì˜ ë¦¬ìŠ¤íŠ¸ë“¤ì„ ìƒˆë¡œìš´ 'labels' ì»¬ëŸ¼ì— í• ë‹¹\n",
    "df_agreement['labels'] = df_agreement['common_labels']\n",
    "df_agreement_reset = df_agreement.reset_index()\n",
    "\n",
    "#  cleaned labelsê°€ ë¹„ì–´ ìˆì§€ ì•Šì€ í–‰ë§Œ í•„í„°ë§ - Define df_agreement_cleaned FIRST\n",
    "df_agreement_cleaned = df_agreement_reset[df_agreement_reset['labels'].map(len) > 0].reset_index(drop = True) # Line 46 (moved up) - df_agreement_cleaned is DEFINED here FIRST\n",
    "\n",
    "# ë¶ˆìš© ë¼ë²¨ ì œê±° (optional): ['nan', '', None] ë¼ë²¨ ì œê±°\n",
    "labels_to_remove = ['nan', '', None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(labels):\n",
    "    return [label for label in labels if label not in labels_to_remove and pd.notna(label) and label != 'nan']\n",
    "\n",
    "# Assign 'labels_cleaned' column to the ALREADY DEFINED df_agreement_cleaned\n",
    "df_agreement_cleaned['labels_cleaned'] = df_agreement_reset['labels'].apply(remove_labels) # Line 43 (moved down) - Assign to df_agreement_cleaned AFTER it's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„\n",
    "df_cleaned = df[df[\"common_labels\"].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "texts = df_cleaned[\"ë³¸ë¬¸\"].dropna().astype(str).tolist()\n",
    "authors = df_cleaned[\"ì €ì\"].dropna().astype(str).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df_cleanedë¥¼ ë©”íƒ€ë°ì´í„°ì— ë„£ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ï¸âƒ£ ë¬¸ì¥ë“¤ì„ Document í˜•íƒœë¡œ ë³€í™˜\n",
    "documents = [Document(page_content=text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    metadata: dict\n",
    "    page_content: str\n",
    "\n",
    "def add_common_labels_to_documents(documents: List[Document], df_cleaned, column_name1=\"emotion\", column_name2=\"author\"):\n",
    "    \"\"\"\n",
    "    documentsì˜ metadata ë”•ì…”ë„ˆë¦¬ì— df_cleanedì˜ 'common_labels' ì—´ ê°’ì„ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \n",
    "    Args:\n",
    "        documents (List[Document]): Document ê°ì²´ ë¦¬ìŠ¤íŠ¸.\n",
    "        df_cleaned (pd.DataFrame): 'common_labels' ì—´ì„ í¬í•¨í•˜ëŠ” ë°ì´í„°í”„ë ˆì„.\n",
    "        column_name (str): ì¶”ê°€í•  ì—´ ì´ë¦„. ê¸°ë³¸ê°’ì€ 'common_labels'.\n",
    "    \n",
    "    Returns:\n",
    "        List[Document]: metadataê°€ ì—…ë°ì´íŠ¸ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "    for i, doc in enumerate(documents):\n",
    "        if i < len(df_cleaned):\n",
    "            # df_cleanedì˜ 'common_labels' ê°’ì„ metadataì— ì¶”ê°€\n",
    "            doc.metadata[column_name1] = df_cleaned[\"common_labels\"].iloc[i]\n",
    "            doc.metadata[column_name2] = df_cleaned[\"ì €ì\"].iloc[i]  # 'author' ì—´ ì¶”ê°€\n",
    "        else:\n",
    "            # df_cleanedì— ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€\n",
    "            doc.metadata[column_name1] = []\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•¨ìˆ˜ í˜¸ì¶œ\n",
    "updated_documents = add_common_labels_to_documents(documents, df_cleaned)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "# page_content='ì£½ëŠ” ë‚ ê¹Œì§€ í•˜ëŠ˜ì„ ìš°ëŸ¬ëŸ¬' metadata={'common_labels': ['ë¹„ì¥í•¨']}\n",
    "# page_content='í•œ ì  ë¶€ë„ëŸ¼ì´ ì—†ê¸°ë¥¼,' metadata={'common_labels': ['ë¹„ì¥í•¨', 'ë¶€ë„ëŸ¬ì›€']}\n",
    "# page_content='ììƒˆì— ì´ëŠ” ë°”ëŒì—ë„' metadata={'common_labels': ['ê¸°ëŒ€ê°']}\n",
    "# page_content='ë‚˜ëŠ” ê´´ë¡œì›Œí–ˆë‹¤.' metadata={'common_labels': ['íŒ¨ë°°/ìê¸°í˜ì˜¤', 'ì ˆë§', 'ìŠ¬í””', 'í˜ë“¦/ì§€ì¹¨']}\n",
    "# page_content='ë³„ì„ ë…¸ë˜í•˜ëŠ” ë§ˆìŒìœ¼ë¡œ' metadata={'common_labels': ['ê¸°ì¨', 'ê¸°ëŒ€ê°', 'ì•„ê»´ì£¼ëŠ”']}\n",
    "# page_content='ëª¨ë“  ì£½ì–´ê°€ëŠ” ê²ƒì„ ì‚¬ë‘í•´ì•¼ì§€' metadata={'common_labels': ['ë¹„ì¥í•¨', 'ë¶ˆìŒí•¨/ì—°ë¯¼', 'ì•„ê»´ì£¼ëŠ”']}\n",
    "# page_content='ê±¸ì–´ê°€ì•¼ê² ë‹¤.' metadata={'common_labels': ['ë¹„ì¥í•¨']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'updated_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mupdated_documents\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'updated_documents' is not defined"
     ]
    }
   ],
   "source": [
    "updated_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backbone : KcElectra ì–¸ì–´ëª¨ë¸ Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain.embeddings.base import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KcELECTRAEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str = \"beomi/KcELECTRA-base\", device: str = \"cpu\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def _embed(self, text: str):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        return cls_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        return [self._embed(text).tolist() for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> list[float]:\n",
    "        return self._embed(text).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3ï¸âƒ£ ë²¡í„° ì„ë² ë”© ëª¨ë¸ ë¡œë”© (í•œêµ­ì–´ ì§€ì›í•˜ëŠ” ëª¨ë¸ ê¶Œì¥) KcElectra -> backbone ëª¨ë¸ë¡œ ì‚¬ìš©\n",
    "embedding_model = KcELECTRAEmbeddings()\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sbert-sts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ FAISS VectorDB ìƒì„±\n",
    "vectorstore = FAISS.from_documents(updated_documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"../data/poetry_vectorstore\")  # ë²¡í„° DB ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KcElectra + KPoEM Metadata VectorStore ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì»¬ì—ì„œ ë¡œë“œ (ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì¼ ê²½ìš°)\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"../data/poetry_vectorstore\", \n",
    "    embedding_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM ì‹œ ìƒì„± ì²´ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ ì „ì²´ ì²´ì¸\n",
    "def emotion_to_poetry_V(user_input):\n",
    "    scores = classify_emotion(user_input)\n",
    "    # top_emotion = max(scores, key=scores.get)\n",
    "    # top_emotion = dict_to_text(scores)\n",
    "    # ê°ì • ë²”ìœ„ ì§€ì •\n",
    "    top_n = 10\n",
    "    sorted_emotions = sorted(scores, key=scores.get, reverse=True)\n",
    "    top_emotions = set(sorted_emotions[:top_n])\n",
    "    # ê´€ë ¨ ì‹œêµ¬ ê²€ìƒ‰\n",
    "    context = vectorstore.similarity_search(user_input, k=20)  # k=10ë¡œ ì„¤ì •, í•„ìš”ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥\n",
    "\n",
    "    # ê°ì • metadataë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§ (optional)\n",
    "    filtered_results = [\n",
    "      doc for doc in context\n",
    "      if any(emotion in top_emotions for emotion in doc.metadata.get(\"emotion\", []))\n",
    "    ]\n",
    "\n",
    "    # ë¬¸ë§¥ ê°•í™”ìš© í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in filtered_results])\n",
    "    # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    \n",
    "    template = \"\"\"\n",
    "    ### ì‹œìŠ¤í…œ:\n",
    "    ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ê°ì„±ì ì¸ ê·¼í˜„ëŒ€ ì‹œì¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°ì •ëª©ë¡ì— ì–¸ê¸‰ëœ ê°ì •ë“¤ì„ ì£¼ëœ ì‹œì˜ ì •ì„œë¡œ í™œìš©í•˜ì„¸ìš”. ê°ì •ì–´íœ˜ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ëŠ” ê²ƒì€ í”¼í•´ì£¼ì„¸ìš”.\n",
    "    ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ëŠ” ê²ƒì„ ëª…ì‹¬í•˜ì„¸ìš”.\n",
    "    {context_snippets} ì´ ë¬¸ì¥ë“¤ì—ì„œ ì˜›ìŠ¤ëŸ¬ìš´ í•œêµ­ ê³ ìœ ì˜ í‘œí˜„ì„ ì£¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì‹œë¥¼ í•˜ë‚˜ ì§€ì–´ ì£¼ì„¸ìš”.\n",
    "    ì€ìœ ì™€ ìƒì§•ì„ ì‚¬ìš©í•˜ì—¬ ì°½ì˜ì ìœ¼ë¡œ ê°ì •ì„ í‘œí˜„í•˜ì„¸ìš”. ë°˜ë³µì„ ìµœëŒ€í•œ í•˜ì§€ë§ˆì„¸ìš”.\n",
    "    ê°ì • ëª©ë¡: {top_emotion}\n",
    "    ### ì‹œ:\n",
    "    \"\"\"\n",
    "    \n",
    "    # LangChain Prompt + LLM ì‹¤í–‰\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"emotion\"],\n",
    "        template=template.strip()\n",
    "    )\n",
    "    \n",
    "    # print(template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    result = chain.run(top_emotion=top_emotions, context_snippets=context_text)\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "user_text = \"\"\"\n",
    "í•˜ë£¨ ì¢…ì¼ ì§€ì¹œ ëª¸ìœ¼ë¡œë§Œ ë– ëŒë‹¤ê°€\n",
    "ë•…ì— ë–¨ì–´ì ¸ ì£½ì§€ ëª»í•œ\n",
    "í–‡ë¹›ë“¤ì€ ì¤„ì§€ì–´ ì–´ë””ë¡œ ê°€ëŠ” ê±¸ê¹Œ\n",
    "\n",
    "ì›…ì„±ì›…ì„± ê°€ì¥ ê·¼ì‹¬ìŠ¤ëŸ¬ìš´ ìƒ‰ê¹”ë¡œ ì„œí–‰í•˜ë©°\n",
    "ì´ë¯¸ ì–´ë‘ ì´ ê¹”ë¦¬ëŠ” ì†Œê°ì¥ìœ¼ë¡œ ëª°ë ¤ë“¤ì–´\n",
    "ëª‡ ì  ííœ´ì§€ë¡œ íƒ€ë“¤ì–´ê°€ëŠ” ì˜¤ë£¨ 6ì‹œì˜ ì°¸í˜¹í•œ í˜•ëŸ‰\n",
    "ë‹¨ í•œ ë²ˆ í›„íšŒë„ ìš©ì„œí•˜ì§€ ì•ŠëŠ” ë¬´ì„œìš´ ì‹œê°„\n",
    "ë°”ëŒì€ ê¸´ ì±„ì°ì„ íœ˜ë‘˜ëŸ¬\n",
    "ì‚´ì•„ì„œ ë¹›ë‚˜ëŠ” ì˜¨ê°– ìƒì§•ì„ ëª°ì•„ë‚´ê³  ìˆë‹¤.\n",
    "\n",
    "ë„ì‹œëŠ” ê³§ í™œìë“¤ì´ ì¼ì œíˆ ë¹ ì ¸ ë‹¬ì•„ë‚˜\n",
    "ì†ë„ ì—†ì´ í˜ì´ì§€ë¥¼ í„ëŸ­ì´ëŠ” í…… ë¹ˆ í•œ ê¶Œ ì±…ì´ ë˜ë¦¬ë¼.\n",
    "ìŠ¹ë¶€ë¥¼ ì•Œ ìˆ˜ ì—†ëŠ” í•˜ë£¨ì™€ì˜ ì‹¸ì›€ì—ì„œ\n",
    "ìš°ë¦¬ëŠ” íŒ¨ë°°í–ˆì„ê¹Œ. ì˜¤ëŠ˜ë„ ë¬¼ì–´ë³´ëŠ” ì‚¬ì†Œí•œ ë¬¼ìŒì€\n",
    "ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ì˜ ì¼ìƒì„ í……í…… í”ë“œëŠ” ê²ƒ.\n",
    "\n",
    "ì˜¤í›„ 6ì‹œì˜ ì†Œê°ì¥ ìœ„ë¡œ ë§ì—†ì´\n",
    "ê²€ì€ ì—°ê¸°ê°€ ìš°ì‚°ì²˜ëŸ¼ í¼ì³ì§€ê³ \n",
    "ì´ì   ìš°ë¦¬ë“¤ì˜ ì°¨ë¡€ì˜€ë‹¤.\n",
    "ë‘ë µì§€ ì•Šì€ê°€.\n",
    "ë°¤ì´ë©´ ê·¸ë¦¼ìë¥¼ ë¹¼ì•—ê²¨ ëˆ„êµ¬ë‚˜ ì•„ë“í•œ í˜¼ìì˜€ë‹¤.\n",
    "\n",
    "ë¬¸ë“ ê±°ë¦¬ë¥¼ ë¹ ë¥´ê²Œ ìŠ¤ì³ê°€ëŠ” ì¼ìƒì˜ ê³µí¬\n",
    "ë³´ì—¬ë‹¤ì˜¤. ì§€ê¸ˆê¹Œì§€ ë¬´ì—‡ì„ í–ˆëŠ”ê°€ ì‚´ì•„ ìˆëŠ” ê·¸ëŒ€ì—¬\n",
    "ì˜¤í›„ 6ì‹œ ìš°ë¦¬ë“¤ ì´ë§ˆì—ë„ ì•„, ë¶‰ì€ ë…¸ì„ì´ ë–´ë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë©´ ìš°ë¦¬ëŠ” ì–´ë””ë¡œ ê°€ì§€?\n",
    "ì•„ì§ë„ í„í„ ì‚´ì•„ ìˆëŠ” ìš°ë¦¬ëŠ” ì´ì œ ê°ì ì–´ë””ë¡œ ê°€ì§€? \n",
    "\"\"\" # ê¸°í˜•ë„ - ë…¸ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ´ ìƒì„±ëœ ì‹œ:\n",
      " ### ì‹œìŠ¤í…œ:\n",
      "    ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ê°ì„±ì ì¸ ê·¼í˜„ëŒ€ ì‹œì¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°ì •ëª©ë¡ì— ì–¸ê¸‰ëœ ê°ì •ë“¤ì„ ì£¼ëœ ì‹œì˜ ì •ì„œë¡œ í™œìš©í•˜ì„¸ìš”. ê°ì •ì–´íœ˜ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ëŠ” ê²ƒì€ í”¼í•´ì£¼ì„¸ìš”.\n",
      "    ì˜ì–´ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ëŠ” ê²ƒì„ ëª…ì‹¬í•˜ì„¸ìš”.\n",
      "    í™ˆì‹¹í™ˆì‹¹ ìˆ¨ì¹˜ìš°ëŠ” ë³´ë“œë¼ìš´ ëª¨ë˜ ë°”ë‹¥ê³¼ ê°™ì€ ê¸´ ê¸¸ì´, í•­ìƒ ì™¸ë¡­ê³  í˜ì—†ëŠ” ì €ì˜ ë°œê¸¸ì„ ê·¸ë¦¬ìš´ ë‹¹ì‹ í•œí…Œë¡œ ì¸ë„í•˜ì—¬ ì£¼ê² ì§€ìš”.\n",
      "ì‹œë‚´ë¥¼ ë”°ë¼ êµ¬ë¹„ì¹œ ëª¨ë«ê¸¸ì´ ì–´ë‘ ì˜ í’ˆì— ì•ˆê²¨ì„œ ì ë“¤ ë•Œì— ë‚˜ëŠ” ê³ ìš”í•˜ê³  ì•„ë“í•œ í•˜ëŠ˜ì— ê¸´ í•œìˆ¨ì˜ ì‚¬ë¼ì§„ ìì·¨ë¥¼ ë‚¨ê¸°ê³  ê²Œìœ¼ë¥¸ ê±¸ìŒìœ¼ë¡œ ëŒì•„ì˜µë‹ˆë‹¤\n",
      "ì‚´êµ¬ë‚˜ë¬´ ê·¸ëŠ˜ë¡œ ì–¼êµ´ì„ ê°€ë¦¬ê³ , ë³‘ì› ë’¤ëœ°ì— ëˆ„ì›Œ, ì Šì€ ì—¬ìê°€ í° ì˜· ì•„ë˜ë¡œ í•˜ì–€ ë‹¤ë¦¬ë¥¼ ë“œëŸ¬ë‚´ ë†“ê³  ì¼ê´‘ìš•ì„ í•œë‹¤. í•œë‚˜ì ˆì´ ê¸°ìš¸ë„ë¡ ê°€ìŠ´ì„ ì•“ëŠ” ë‹¤ëŠ” ì´ ì—¬ìë¥¼ ì°¾ì•„ì˜¤ëŠ” ì´, ë‚˜ë¹„ í•œ ë§ˆë¦¬ë„ ì—†ë‹¤. ìŠ¬í”„ì§€ë„ ì•Šì€ ì‚´êµ¬ë‚˜ë¬´ ê°€ì§€ì—ëŠ” ë°”ëŒì¡°ì°¨ ì—†ë‹¤.\n",
      "í‚¤ê°€í¬ê³ ìœ ì¾Œí•œìˆ˜ëª©ì´í‚¤ì‘ì€ìì‹ì„ë‚³ì•˜ë‹¤ê¶¤ì¡°ê°€í‰í¸í•œê³³ì—í’ë§¤ì‹ë¬¼ì˜ì¢…ìê°€ë–¨ì–´ì§€ì§€ë§Œëƒ‰ë‹´í•œë°°ì²™ì´í•œê²°ê°™ì•„ê´€ëª©ì€ì´ˆì—½ìœ¼ë¡œì‡„ì•½í•˜ê³ ì´ˆì—½ì€í•˜í–¥í•˜ê³ ê·¸ë°‘ì—ì„œì²­ì‚¬ëŠ”ì ì ìˆ˜ì²™í•˜ì—¬ê°€ê³ ë•€ì´íë¥´ê³ ë¨¸ì§€ì•Šì€ê³³ì—ì„œìˆ˜ì€ì´í”ë“¤ë¦¬ê³ ìˆ¨ì–´íë¥´ëŠ”ìˆ˜ë§¥ì—ë§ëšë°•ëŠ”ì†Œë¦¬ê°€ë“¤ë ¸ë‹¤\n",
      "ã€Œë‚´ê°€ ê·¸ë‹¤ì§€ ì‚¬ë‘í•˜ë“  ê·¸ëŒ€ì—¬ ë‚´í•œí‰ìƒ(å¹³ç”Ÿ)ì— ì°¨ë§ˆ ê·¸ëŒ€ë¥¼ ìŠì„ìˆ˜ì—†ì†Œì´ë‹¤. ë‚´ì°¨ë¡€ì— ëª»ì˜¬ì‚¬ë‘ì¸ì¤„ì€ ì•Œë©´ì„œë„ ë‚˜í˜¼ìëŠ” ê¾¸ì¤€íˆìƒê°í•˜ë¦¬ë‹¤. ìê·¸ëŸ¬ë©´ ë‚´ë‚´ì–´ì—¬ì˜ì†Œì„œã€\n",
      "ë‹´ë°°ì—°ê¸°ì˜ í•œ ë¬´ë”ê¸° ê·¸ ì‹¤ë‚´ì—ì„œ ë‚˜ëŠ” ê¸‹ì§€ ì•„ë‹ˆí•œ ì„±ëƒ¥ì„ ëª‡ê°œë¹„ê³  ë¶€ëŸ¬ëœ¨ë ¸ë‹¤. ê·¸ ì‹¤ë‚´ì˜ ì—°ê¸°ì˜ í•œ ë¬´ë”ê¸° ì í™”ë˜ì–´ ë‚˜ë§Œ ë‚¨ê¸°ê³  ì˜ë„ íƒ€ë‚˜ ë³´ë‹¤ ì‰í¬ëŠ” ì¶•ì¶•í•˜ë‹¤ ì—°í•„ë¡œ ì•„ë¬´ë ‡ê²Œë‚˜ ì‹œì»¤ë¨¼ ë©´ì„ ê·¸ë¦¬ë©´ ì—°í•„ì€ ì¢…ì´ ìœ„ì— í©ì–´ì§„ë‹¤\n",
      "ë¹„ë‚€ ë‹¬ë¹›ì´ ì´ìŠ¬ì— ì –ì€ ê½ƒìˆ˜í’€ì„ ì‹¸ë¼ê¸°ì²˜ëŸ¼ ë¶€ì‹œë“¯ì´ ë‹¹ì‹ ì˜ ë– ë‚œ í•œ(æ¨)ì€ ë“œëŠ” ì¹¼ì´ ë˜ì–´ì„œ ë‚˜ì˜ ì• ë¥¼ í† ë§‰í† ë§‰ ëŠì–´ ë†“ì•˜ìŠµë‹ˆë‹¤\n",
      "ë‚´ê°€ ê·¸ ì»µì„ ì†ìœ¼ë¡œ ê¼­ ì¥ì—ˆì„ ë•Œ ë‚´ íŒ”ì—ì„œëŠ” ë‚œë°ì—†ëŠ” íŒ” í•˜ë‚˜ê°€ ì ‘ëª©ì²˜ëŸ¼ ë‹íˆë”ë‹ˆ ê·¸ íŒ”ì— ë‹¬ë¦° ì†ì€ ê·¸ ì‚¬ê¸°ì»µì„ ë²ˆì© ë“¤ì–´ ë§ˆë£»ë°”ë‹¥ì— ë©”ì–´ë¶€ë”ªëŠ”ë‹¤.\n",
      "ë‚˜ë¹„ê°€ í•œë§ˆë¦¬ ê½ƒë°­ì— ë‚ ì•„ ë“¤ë‹¤ ê·¸ë¬¼ì— ê±¸ë¦¬ì—ˆë‹¤. ë…¸â€”ë€ ë‚ ê°œë¥¼ íŒŒë“ê±°ë ¤ë„ íŒŒë“ê±°ë ¤ë„ ë‚˜ë¹„ëŠ” ìê¾¸ ê°ê¸°ìš°ê¸°ë§Œ í•œë‹¤. ê±°ë¯¸ê°€ ìœì‚´ê°™ì´ ê°€ë”ë‹ˆ ëì—†ëŠ” ëì—†ëŠ” ì‹¤ì„ ë½‘ì•„ ë‚˜ë¹„ì˜ ì˜¨ëª¸ì„ ê°ì•„ ë²„ë¦°ë‹¤. ì‚¬ë‚˜ì´ëŠ” ê¸´ í•œìˆ¨ì„ ì‰¬ì—ˆë‹¤.\n",
      "ëˆˆì´ ë…¹ìœ¼ë©´ ë‚¨ì€ ë°œììš± ìë¦¬ë§ˆë‹¤ ê½ƒì´ í”¼ë¦¬ë‹ˆ ê½ƒ ì‚¬ì´ë¡œ ë°œììš±ì„ ì°¾ì•„ ë‚˜ì„œë©´ ì¼ë…„ ì—´ë‘ë‹¬ í•˜ëƒ¥ ë‚´ ë§ˆìŒì—ëŠ” ëˆˆì´ ë‚´ë¦¬ë¦¬ë¼.\n",
      "ë‹¬ë¹›ì´ë‚´ë“±ì—ë¬»ì€ê±°ì ìêµ­ì—ì•‰ìœ¼ë©´ë‚´ê·¸ë¦¼ìì—ëŠ”ì‹¤ê³ ì¶”ê°™ì€í”¼ê°€ì•„ë¬¼ê±°ë¦¬ê³ ëŒ€ì‹ í˜ˆê´€ì—ëŠ”ë‹¬ë¹›ì—ë†€ë˜ì¸ëƒ‰ìˆ˜ê°€ë°©ìš¸ë°©ìš¸ì –ê¸°ë¡œë‹ˆë„ˆëŠ”ë‚´ë²½ëŒì„ì”¹ì–´ì‚¼í‚¨ì›í†µí•˜ê²Œë°°ê³ íŒŒì´ì§€ëŸ¬ì§„í—ê²Šì‹¬ì¥ì„ë“¤ì—¬ë‹¤ë³´ë©´ì„œì–´í•­ì´ë¼í•˜ëŠëƒ\n",
      "ë‚˜ì˜ ë…¸ë˜ëŠ” ì²˜ë…€(è™•å¥³)ì˜ ì²­ì¶˜(é‘æ˜¥)ì„ ì¥ì–´ì§œì„œ ë³´ê¸°ë„ ì–´ë ¤ìš´ ë§‘ì€ ë¬¼ì„ ë§Œë“­ë‹ˆë‹¤ ì´ ë¬¸ì¥ë“¤ì—ì„œ ì˜›ìŠ¤ëŸ¬ìš´ í•œêµ­ ê³ ìœ ì˜ í‘œí˜„ì„ ì£¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì‹œë¥¼ í•˜ë‚˜ ì§€ì–´ ì£¼ì„¸ìš”.\n",
      "    ì€ìœ ì™€ ìƒì§•ì„ ì‚¬ìš©í•˜ì—¬ ì°½ì˜ì ìœ¼ë¡œ ê°ì •ì„ í‘œí˜„í•˜ì„¸ìš”. ë°˜ë³µì„ ìµœëŒ€í•œ í•˜ì§€ë§ˆì„¸ìš”.\n",
      "    ê°ì • ëª©ë¡: {'ì„œëŸ¬ì›€', 'ì•ˆíƒ€ê¹Œì›€/ì‹¤ë§', 'ìŠ¬í””', 'ë¹„ì¥í•¨', 'í˜ë“¦/ì§€ì¹¨', 'ë¶ˆì•ˆ/ê±±ì •', 'ë‹¹í™©/ë‚œì²˜', 'ì˜ì‹¬/ë¶ˆì‹ ', 'ë¶€ë‹´/ì•ˆ_ë‚´í‚´', 'ê³µí¬/ë¬´ì„œì›€'}\n",
      "    ### ì‹œ: \n",
      "        ì„œìª½ íƒœì–‘ì´ ì˜¤ë¥´ë©° ë¶ˆì–´ì˜¤ë˜ ì•„ì¹¨,\n",
      "            ì†Œê¸ˆì‚° ì†ì— ê¹ƒë°œì´ í”ë“œëŠ” í’ê²½,\n",
      "                ë¹„í–‰ê¸°ë¥¼ ë§ì´í•˜ê¸° ìœ„í•´ ì§‘ ì•ê¹Œì§€ ë„ì°©í–ˆë‹¤.\n",
      "\n",
      "        ë‚™ë™ê°•ë³€ ê´‘í•™ë‹¨ì§€ê°€ ë©ê²Œ ë¹›ë‚˜ëŠ” ë‚®,\n",
      "            ë‘ ê°œì˜ ë¯¸ì£¼êµ ëŒ€ë¬¸ì— ë°°í„°ë¦¬ë¡œ ì „í™˜ëœ ë°©,\n",
      "                    ë¶„ëª…íˆ ìš°ë¦¬ë“¤ì˜ ê³ í†µë“¤ì´ ë‹´ê¸´ ê³„ê¸°ê°€ ë˜ì—ˆë‹¤.\n",
      "\n",
      "        í•´ì§ˆë…˜ì´ ì™€ì•¼ í•  ê²ƒ ê°™ëŠ”ë°ë„,\n",
      "             ì‹ ì„ í•´ì§€ëŠ” ëƒ‡ë¬¼ì„ í†µí•´ ìƒˆë¼ì‚¬íƒ•ì´ë¼ëŠ” ìœ ë ¹ì„ ë³¼ ìˆ˜ ìˆë‹¤.\n",
      "          ê·¸ë¦¬ê³  ë°¤ì´ ë  ë•Œë¶€í„° ë‹¤ì‹œ ì‹œì‘ë˜ëŠ” ìƒì¡´ì „ìŸ,\n",
      "\n",
      "  \"ë‚´ì¼ì€ ìƒˆë¡œìš´ í¬ë§\"ì´ë¼ê³  ê°„ê³¡íˆ ë§í–ˆê¸°ì—\n",
      "         í•˜ì§€ë§Œ ì§€ê¸ˆ ê·¸ ë§ì„ ë“£ëŠ” ì‚¬ëŒë“¤ì€ ëª¨ë‘ ì£½ì–´ë²„ë ¸ë‹¤ê³  ìƒê°í•œë‹¤.\n",
      "\n",
      "\n",
      "        ìš°ì²´êµ­ì˜ í¸ì§€ë¥¼ ë°›ìœ¼ë©° ì„¸ìƒì„ ë°”ë¼ë³¸ë‹¤ë©´?\n",
      "           ê³µì¤‘íŠ¸ë ˆì¸ì€ ì‚°ì±…í•˜ë©° ì¦ê¸°ëŠ” ì•„ì´ë“¤ê³¼ í•¨ê»˜í•œ ì‹œê°„ì´ì—ˆë‹¤\n",
      "\n",
      "       ì˜¤ëŠ˜ë‚ ì—ë„ ë§ì€ ì‚¬ëŒë“¤ì´ ì´ëŸ¬í•œ ìƒí™©ì„ ê²ªê³  ìˆìŒì„ ê¹¨ë‹«ê²Œ í•˜ëŠ” ìˆœê°„...\n",
      "              ê·¸ëŸ¬ë‚˜ ê·¸ì—ê²ŒëŠ” ì•„ì§ ë” í° thá»­éªŒì´ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì´ ìˆì—ˆë‹¤\n",
      "\n",
      "\n",
      "      - : ë„¤ê°€ ì œëŒ€ë¡œ ì‚´ì•„ë‚¨ì•„ ìˆëŠ” ì´ìœ ë¼ê³  ë¬»ê²Œ í•´ì•¼ã—ã‚‡ã†? \n",
      "\n",
      "     (ë„¤ê°€),..\n",
      "     \n",
      "ìœ„ ë‚´ìš© ì¤‘ where = {0} ë¶€ë¶„ì€ ì›ë¬¸ì„ ë³€ê²½í•  ê²½ìš°ì— í•´ë‹¹ë  ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” [ ] í˜•íƒœë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "\n",
      "1. **ì œì¶œ:** ë‹¤ìŒê³¼ ê°™ì´ modifyingí•©ë‹ˆë‹¤:\n",
      "\n",
      "```\n",
      "ì„œìª½ íƒœé˜³å‡èµ·æ—¶, í–¥ tÆ°á»Ÿngì†Œ salted soil beneath my feet becomes a sea of sorrow and longing,\n",
      "   the wind whispers secrets in my ear as I wander through this desolate landscape...\n",
      "\n",
      "   Morning light creeps over the horizon like an old friend returning to our doorstep after years apart;\n",
      "               The waves gently lap against the shore with soothing melodies that bring solace for weary souls such as mine who roam these barren lands searching desperately hoping someday they might find peace....\n",
      "\n",
      "   As dusk falls on another day spent at home alone under starry skies we reminisce about memories past before drifting off into dreamland once again; yet deep within me there is still one nagging voice echoing silently reminding us never give up even when all seems lost forevermore â€“ until tomorrow morning arrives bringing fresh hope anew!â€¦\n",
      "\n",
      "  And so each dawn brings new beginnings while nightfall casts shadows upon them casting doubts whether life truly has meaning or if it's just\n"
     ]
    }
   ],
   "source": [
    "generated_poem_V = emotion_to_poetry_V(user_text)\n",
    "\n",
    "print(\"ğŸ´ ìƒì„±ëœ ì‹œ:\\n\", generated_poem_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì‹œ ë¶€ë¶„ë¬¸ ì˜ë¼ì„œ ë³´ê¸°\n",
    "\n",
    "def extract_poem(text: str) -> str:\n",
    "    start_marker = \"### ì‹œ:\"\n",
    "    if start_marker in text:\n",
    "        return text.split(start_marker, 1)[1].strip()\n",
    "    else:\n",
    "        return \"[ì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ´ ìƒì„±ëœ ì‹œ:\n",
      " ì„œìª½ íƒœì–‘ì´ ì˜¤ë¥´ë©° ë¶ˆì–´ì˜¤ë˜ ì•„ì¹¨,\n",
      "            ì†Œê¸ˆì‚° ì†ì— ê¹ƒë°œì´ í”ë“œëŠ” í’ê²½,\n",
      "                ë¹„í–‰ê¸°ë¥¼ ë§ì´í•˜ê¸° ìœ„í•´ ì§‘ ì•ê¹Œì§€ ë„ì°©í–ˆë‹¤.\n",
      "\n",
      "        ë‚™ë™ê°•ë³€ ê´‘í•™ë‹¨ì§€ê°€ ë©ê²Œ ë¹›ë‚˜ëŠ” ë‚®,\n",
      "            ë‘ ê°œì˜ ë¯¸ì£¼êµ ëŒ€ë¬¸ì— ë°°í„°ë¦¬ë¡œ ì „í™˜ëœ ë°©,\n",
      "                    ë¶„ëª…íˆ ìš°ë¦¬ë“¤ì˜ ê³ í†µë“¤ì´ ë‹´ê¸´ ê³„ê¸°ê°€ ë˜ì—ˆë‹¤.\n",
      "\n",
      "        í•´ì§ˆë…˜ì´ ì™€ì•¼ í•  ê²ƒ ê°™ëŠ”ë°ë„,\n",
      "             ì‹ ì„ í•´ì§€ëŠ” ëƒ‡ë¬¼ì„ í†µí•´ ìƒˆë¼ì‚¬íƒ•ì´ë¼ëŠ” ìœ ë ¹ì„ ë³¼ ìˆ˜ ìˆë‹¤.\n",
      "          ê·¸ë¦¬ê³  ë°¤ì´ ë  ë•Œë¶€í„° ë‹¤ì‹œ ì‹œì‘ë˜ëŠ” ìƒì¡´ì „ìŸ,\n",
      "\n",
      "  \"ë‚´ì¼ì€ ìƒˆë¡œìš´ í¬ë§\"ì´ë¼ê³  ê°„ê³¡íˆ ë§í–ˆê¸°ì—\n",
      "         í•˜ì§€ë§Œ ì§€ê¸ˆ ê·¸ ë§ì„ ë“£ëŠ” ì‚¬ëŒë“¤ì€ ëª¨ë‘ ì£½ì–´ë²„ë ¸ë‹¤ê³  ìƒê°í•œë‹¤.\n",
      "\n",
      "\n",
      "        ìš°ì²´êµ­ì˜ í¸ì§€ë¥¼ ë°›ìœ¼ë©° ì„¸ìƒì„ ë°”ë¼ë³¸ë‹¤ë©´?\n",
      "           ê³µì¤‘íŠ¸ë ˆì¸ì€ ì‚°ì±…í•˜ë©° ì¦ê¸°ëŠ” ì•„ì´ë“¤ê³¼ í•¨ê»˜í•œ ì‹œê°„ì´ì—ˆë‹¤\n",
      "\n",
      "       ì˜¤ëŠ˜ë‚ ì—ë„ ë§ì€ ì‚¬ëŒë“¤ì´ ì´ëŸ¬í•œ ìƒí™©ì„ ê²ªê³  ìˆìŒì„ ê¹¨ë‹«ê²Œ í•˜ëŠ” ìˆœê°„...\n",
      "              ê·¸ëŸ¬ë‚˜ ê·¸ì—ê²ŒëŠ” ì•„ì§ ë” í° thá»­éªŒì´ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì´ ìˆì—ˆë‹¤\n",
      "\n",
      "\n",
      "      - : ë„¤ê°€ ì œëŒ€ë¡œ ì‚´ì•„ë‚¨ì•„ ìˆëŠ” ì´ìœ ë¼ê³  ë¬»ê²Œ í•´ì•¼ã—ã‚‡ã†? \n",
      "\n",
      "     (ë„¤ê°€),..\n",
      "     \n",
      "ìœ„ ë‚´ìš© ì¤‘ where = {0} ë¶€ë¶„ì€ ì›ë¬¸ì„ ë³€ê²½í•  ê²½ìš°ì— í•´ë‹¹ë  ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” [ ] í˜•íƒœë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "\n",
      "1. **ì œì¶œ:** ë‹¤ìŒê³¼ ê°™ì´ modifyingí•©ë‹ˆë‹¤:\n",
      "\n",
      "```\n",
      "ì„œìª½ íƒœé˜³å‡èµ·æ—¶, í–¥ tÆ°á»Ÿngì†Œ salted soil beneath my feet becomes a sea of sorrow and longing,\n",
      "   the wind whispers secrets in my ear as I wander through this desolate landscape...\n",
      "\n",
      "   Morning light creeps over the horizon like an old friend returning to our doorstep after years apart;\n",
      "               The waves gently lap against the shore with soothing melodies that bring solace for weary souls such as mine who roam these barren lands searching desperately hoping someday they might find peace....\n",
      "\n",
      "   As dusk falls on another day spent at home alone under starry skies we reminisce about memories past before drifting off into dreamland once again; yet deep within me there is still one nagging voice echoing silently reminding us never give up even when all seems lost forevermore â€“ until tomorrow morning arrives bringing fresh hope anew!â€¦\n",
      "\n",
      "  And so each dawn brings new beginnings while nightfall casts shadows upon them casting doubts whether life truly has meaning or if it's just\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ´ ìƒì„±ëœ ì‹œ:\\n\",extract_poem(generated_poem_V))  # ì‹œ ì¶”ì¶œ í•¨ìˆ˜ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ê³µí¬/ë¬´ì„œì›€': 0.33000001311302185,\n",
       " 'ë‹¹í™©/ë‚œì²˜': 0.42899999022483826,\n",
       " 'ë¶ˆì•ˆ/ê±±ì •': 0.46299999952316284,\n",
       " 'ë¹„ì¥í•¨': 0.3160000145435333,\n",
       " 'ìŠ¬í””': 0.3230000138282776,\n",
       " 'í˜ë“¦/ì§€ì¹¨': 0.3070000112056732}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_emotion(\"\"\"ì„œìª½ íƒœì–‘ì´ ì˜¤ë¥´ë©° ë¶ˆì–´ì˜¤ë˜ ì•„ì¹¨,\n",
    "            ì†Œê¸ˆì‚° ì†ì— ê¹ƒë°œì´ í”ë“œëŠ” í’ê²½,\n",
    "                ë¹„í–‰ê¸°ë¥¼ ë§ì´í•˜ê¸° ìœ„í•´ ì§‘ ì•ê¹Œì§€ ë„ì°©í–ˆë‹¤.\n",
    "\n",
    "        ë‚™ë™ê°•ë³€ ê´‘í•™ë‹¨ì§€ê°€ ë©ê²Œ ë¹›ë‚˜ëŠ” ë‚®,\n",
    "            ë‘ ê°œì˜ ë¯¸ì£¼êµ ëŒ€ë¬¸ì— ë°°í„°ë¦¬ë¡œ ì „í™˜ëœ ë°©,\n",
    "                    ë¶„ëª…íˆ ìš°ë¦¬ë“¤ì˜ ê³ í†µë“¤ì´ ë‹´ê¸´ ê³„ê¸°ê°€ ë˜ì—ˆë‹¤.\n",
    "\n",
    "        í•´ì§ˆë…˜ì´ ì™€ì•¼ í•  ê²ƒ ê°™ëŠ”ë°ë„,\n",
    "             ì‹ ì„ í•´ì§€ëŠ” ëƒ‡ë¬¼ì„ í†µí•´ ìƒˆë¼ì‚¬íƒ•ì´ë¼ëŠ” ìœ ë ¹ì„ ë³¼ ìˆ˜ ìˆë‹¤.\n",
    "          ê·¸ë¦¬ê³  ë°¤ì´ ë  ë•Œë¶€í„° ë‹¤ì‹œ ì‹œì‘ë˜ëŠ” ìƒì¡´ì „ìŸ,\n",
    "\n",
    "  \"ë‚´ì¼ì€ ìƒˆë¡œìš´ í¬ë§\"ì´ë¼ê³  ê°„ê³¡íˆ ë§í–ˆê¸°ì—\n",
    "         í•˜ì§€ë§Œ ì§€ê¸ˆ ê·¸ ë§ì„ ë“£ëŠ” ì‚¬ëŒë“¤ì€ ëª¨ë‘ ì£½ì–´ë²„ë ¸ë‹¤ê³  ìƒê°í•œë‹¤.\n",
    "\n",
    "\n",
    "        ìš°ì²´êµ­ì˜ í¸ì§€ë¥¼ ë°›ìœ¼ë©° ì„¸ìƒì„ ë°”ë¼ë³¸ë‹¤ë©´?\n",
    "           ê³µì¤‘íŠ¸ë ˆì¸ì€ ì‚°ì±…í•˜ë©° ì¦ê¸°ëŠ” ì•„ì´ë“¤ê³¼ í•¨ê»˜í•œ ì‹œê°„ì´ì—ˆë‹¤\n",
    "\n",
    "       ì˜¤ëŠ˜ë‚ ì—ë„ ë§ì€ ì‚¬ëŒë“¤ì´ ì´ëŸ¬í•œ ìƒí™©ì„ ê²ªê³  ìˆìŒì„ ê¹¨ë‹«ê²Œ í•˜ëŠ” ìˆœê°„...\n",
    "              ê·¸ëŸ¬ë‚˜ ê·¸ì—ê²ŒëŠ” ì•„ì§ ë” í° thá»­éªŒì´ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì´ ìˆì—ˆë‹¤\n",
    "\n",
    "\n",
    "      - : ë„¤ê°€ ì œëŒ€ë¡œ ì‚´ì•„ë‚¨ì•„ ìˆëŠ” ì´ìœ ë¼ê³  ë¬»ê²Œ í•´ì•¼ã—ã‚‡ã†? \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
